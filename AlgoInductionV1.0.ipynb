{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AlgoInduction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vFt-j09rG9r",
        "colab_type": "text"
      },
      "source": [
        "**Stage 0: Set up**     \n",
        "(Importing the modules required) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLZnxZ5AYalM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "29b918ad-5418-4817-8243-af22302d3679"
      },
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "from sklearn.impute import KNNImputer\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from pprint import pprint\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn import preprocessing as pp\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression\n",
        "! pip install eli5\n",
        "import eli5\n",
        "from eli5.sklearn import PermutationImportance\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting eli5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/2f/c85c7d8f8548e460829971785347e14e45fa5c6617da374711dec8cb38cc/eli5-0.10.1-py2.py3-none-any.whl (105kB)\n",
            "\r\u001b[K     |███                             | 10kB 14.4MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 112kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from eli5) (1.18.5)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from eli5) (0.22.2.post1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from eli5) (1.12.0)\n",
            "Requirement already satisfied: attrs>16.0.0 in /usr/local/lib/python3.6/dist-packages (from eli5) (19.3.0)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.6/dist-packages (from eli5) (0.8.7)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from eli5) (1.4.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from eli5) (0.10.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from eli5) (2.11.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->eli5) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->eli5) (1.1.1)\n",
            "Installing collected packages: eli5\n",
            "Successfully installed eli5-0.10.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n",
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxJizpbm4ICN",
        "colab_type": "text"
      },
      "source": [
        "**Stage 1: Data-preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7o7Pmo-f7N6x",
        "colab_type": "text"
      },
      "source": [
        "1.1 Loading any required dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tZwInTU4CoX",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "8bf8f03d-a455-4d61-c8e9-c77d5609ca08"
      },
      "source": [
        "#Any dataset of the user's choice can be uploaded by changing file name \n",
        "#df = pd.read_excel(\"df_stud_simplest_train.xlsx\")\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "name=\"df_stud_simplest_train_PP.xlsx\"\n",
        "df = pd.read_excel(name)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8f6199ea-0dc6-496b-9eaa-4f87f4bc26c1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8f6199ea-0dc6-496b-9eaa-4f87f4bc26c1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving df_stud_simplest_train_PP.xlsx to df_stud_simplest_train_PP (1).xlsx\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOTkFfds7ak-",
        "colab_type": "text"
      },
      "source": [
        "1.2 Imputing the dataset to fill any missing values, if the datset uploaded was incomplete. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNufrYfMEiT7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "0cef8a17-e1c3-4b05-d382-2e3bf0d3caa2"
      },
      "source": [
        "choice_for_missing_data = int(input(\"If there are missing values in the dataset, you can choose to either impute (enter '1') them or to use only rows without missing data (enter '0'). \"))\n",
        "if (choice_for_missing_data == 1):\n",
        "  df.replace(r'^\\s*$', np.nan, regex=True)\n",
        "  imputer = KNNImputer(n_neighbors=2)\n",
        "  filled = imputer.fit_transform(df)\n",
        "  df_filled = pd.DataFrame(filled, columns = df.columns)\n",
        "  df_filled = df_filled.drop(columns=\"index\")\n",
        "  if (df_filled.isnull().sum().sum() == 0 ):\n",
        "    print(\"Dataset has been succesfully imputed.\")\n",
        "    print(df_filled)\n",
        "elif (choice_for_missing_data == 0):\n",
        "  df.dropna(axis = 0, how='any',inplace=True)\n",
        "  df_filled = df.copy(deep='True')\n",
        "  if (df.isnull().sum().sum() == 0 ):\n",
        "    print(\"Dataset has been succesfully imputed.\")\n",
        "    print(df_filled)\n",
        "else:\n",
        "  print(\"Wrong input for choice, enter either 0 or 1\")\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "If there are missing values in the dataset, you can choose to either impute (enter '1') them or to use only rows without missing data (enter '0'). 0\n",
            "Dataset has been succesfully imputed.\n",
            "       ComplexConvergenceDum  NSolutions  ...  GroupDum  high_std_experience_dum\n",
            "10                         0          32  ...         1                      0.0\n",
            "23                         0          15  ...         1                      0.0\n",
            "66                         0         271  ...         1                      1.0\n",
            "103                        0          24  ...         1                      0.0\n",
            "188                        0           6  ...         1                      0.0\n",
            "...                      ...         ...  ...       ...                      ...\n",
            "57735                      0           4  ...         1                      0.0\n",
            "57796                      0          77  ...         1                      0.0\n",
            "57843                      0          68  ...         1                      1.0\n",
            "57864                      0          22  ...         1                      0.0\n",
            "57876                      0          24  ...         1                      1.0\n",
            "\n",
            "[1739 rows x 15 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vc9M71rCBXa3",
        "colab_type": "text"
      },
      "source": [
        "1.3 Splitting the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEI0phjVOnO2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7134a628-d11f-48a3-c81a-bceed0a2813f"
      },
      "source": [
        "#Splitting dataset equally into train and test \n",
        "\n",
        "target_name = input(\"Enter column name that is the target variable:\") \n",
        "\n",
        "X_train_df = df_filled.copy(deep=True)\n",
        "selected_columns = X_train_df[[target_name]]\n",
        "Y_train_df = selected_columns.copy()\n",
        "X_train_df = X_train_df.drop(columns=target_name)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter column name that is the target variable:PrivateLeaderboardScore\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBo6OS8oEfMh",
        "colab_type": "text"
      },
      "source": [
        "**Stage 2: Feature selection and polynomial creation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSLfZW7kExtr",
        "colab_type": "text"
      },
      "source": [
        "2.1 Hyperparameter tuning of random forest and MLP using K-fold cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-u9M-BzgNAr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "36d34255-5e03-4789-98e3-489bc244fa38"
      },
      "source": [
        "type_of_data = int(input(\"Enter 1 the target variable is categorical. Enter 0 if the target variable is continuous: \"))\n",
        "if (type_of_data == 1):\n",
        "  rf = RandomForestClassifier()\n",
        "  mlp = MLPClassifier(max_iter=100)\n",
        "elif (type_of_data == 0):\n",
        "  rf = RandomForestRegressor()\n",
        "  mlp = MLPRegressor(max_iter=100)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter 1 the target variable is categorical. Enter 0 if the target variable is continuous: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaR_4rFvweRb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5cc30775-03cd-4001-fa41-ce02372a8f03"
      },
      "source": [
        "print('Parameters currently in use, before hyperparameter tuning:\\n')\n",
        "pprint(rf.get_params())\n",
        "\n",
        "# All possibile values each parameter can take\n",
        "\n",
        "# Number of trees in random forest\n",
        "n_estimators = []\n",
        "n_estimators.append((int(input(\"Enter number of estimators, ie. number of trees in random forest:\"))))\n",
        "\n",
        "# Number of features to consider at every split\n",
        "max_features = ['auto']\n",
        "# Maximum number of levels in tree\n",
        "max_depth = []\n",
        "max_depth.append((int(input(\"Enter a number from 1-10 for maximum number of levels in a tree:\"))))\n",
        "# Minimum number of samples required to split a node\n",
        "min_samples_split = [2, 5, 10]\n",
        "# Minimum number of samples required at each leaf node\n",
        "min_samples_leaf = [1, 2, 4]\n",
        "# Method of selecting samples for training each tree\n",
        "bootstrap = [True]\n",
        "# Create the random grid\n",
        "random_grid = {'n_estimators': n_estimators,\n",
        "               'max_features': max_features,\n",
        "               'max_depth': max_depth,\n",
        "               'min_samples_split': min_samples_split,\n",
        "               'min_samples_leaf': min_samples_leaf,\n",
        "               'bootstrap': bootstrap}\n",
        "print(\"Randomised grid to test for the best hyperparameter:\\n\")\n",
        "pprint(random_grid)\n",
        "\n",
        "\n",
        "  \n",
        "# Random search using grid of parameters, using 3 fold cross validation, \n",
        "# search across 50 different combinations, and use all available cores\n",
        "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 50, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
        "# Fit the random search model\n",
        "rf_random.fit(X_train_df, Y_train_df)\n",
        "print(\"\\n The best parameters for the random forest, after hyperparameter tuning are:\")\n",
        "pprint(rf_random.best_params_)\n",
        "\n",
        "feature_list = list(X_train_df.columns)\n",
        "importances = list(rf_random.best_estimator_.feature_importances_)\n",
        "\n",
        "feature_importances = [(feature, round(importance, 4)) for feature, importance in zip(feature_list, importances)]\n",
        "\n",
        "# Sort the feature importances by most important first\n",
        "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
        "\n",
        "# Print out the feature and importances \n",
        "print(\"\\n Features and their importance:\")\n",
        "pprint(feature_importances)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameters currently in use, before hyperparameter tuning:\n",
            "\n",
            "{'bootstrap': True,\n",
            " 'ccp_alpha': 0.0,\n",
            " 'criterion': 'mse',\n",
            " 'max_depth': None,\n",
            " 'max_features': 'auto',\n",
            " 'max_leaf_nodes': None,\n",
            " 'max_samples': None,\n",
            " 'min_impurity_decrease': 0.0,\n",
            " 'min_impurity_split': None,\n",
            " 'min_samples_leaf': 1,\n",
            " 'min_samples_split': 2,\n",
            " 'min_weight_fraction_leaf': 0.0,\n",
            " 'n_estimators': 100,\n",
            " 'n_jobs': None,\n",
            " 'oob_score': False,\n",
            " 'random_state': None,\n",
            " 'verbose': 0,\n",
            " 'warm_start': False}\n",
            "Enter number of estimators, ie. number of trees in random forest:50\n",
            "Enter a number from 1-10 for maximum number of levels in a tree:4\n",
            "Randomised grid to test for the best hyperparameter:\n",
            "\n",
            "{'bootstrap': [True],\n",
            " 'max_depth': [4],\n",
            " 'max_features': ['auto'],\n",
            " 'min_samples_leaf': [1, 2, 4],\n",
            " 'min_samples_split': [2, 5, 10],\n",
            " 'n_estimators': [50]}\n",
            "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:281: UserWarning: The total space of parameters 9 is smaller than n_iter=50. Running 9 iterations. For exhaustive searches, use GridSearchCV.\n",
            "  % (grid_size, self.n_iter, grid_size), UserWarning)\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " The best parameters for the random forest, after hyperparameter tuning are:\n",
            "{'bootstrap': True,\n",
            " 'max_depth': 4,\n",
            " 'max_features': 'auto',\n",
            " 'min_samples_leaf': 4,\n",
            " 'min_samples_split': 10,\n",
            " 'n_estimators': 50}\n",
            "\n",
            " Features and their importance:\n",
            "[('NSolutions', 0.4545),\n",
            " ('QualitativeDivergence', 0.4128),\n",
            " ('std_experience', 0.0478),\n",
            " ('high_std_experience_dum', 0.0245),\n",
            " ('avg_experience', 0.0211),\n",
            " ('GroupSize', 0.0164),\n",
            " ('NumScoredSubmissions', 0.0095),\n",
            " ('skew_gold_dum_pri_count', 0.006),\n",
            " ('skew_experience', 0.0041),\n",
            " ('convergence_var', 0.0021),\n",
            " ('ComplexConvergenceDum', 0.0006),\n",
            " ('std_gold_dum_pri_count', 0.0006),\n",
            " ('avg_gold_dum_pri_count', 0.0),\n",
            " ('GroupDum', 0.0)]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:    3.7s finished\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py:739: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  self.best_estimator_.fit(X, y, **fit_params)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6XY7_ZJJq40",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "58a2b268-7a32-4514-c649-452dc8162ac5"
      },
      "source": [
        "parameter_space = {\n",
        "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
        "    'alpha': [0.0001, 0.05],\n",
        "}\n",
        "\n",
        "clf = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=3)\n",
        "clf.fit(X_train_df, Y_train_df)\n",
        "\n",
        "# Best parameter set\n",
        "print('Best parameters found:\\n')\n",
        "pprint(clf.best_params_)\n",
        "print('\\n')\n",
        "\n",
        "\n",
        "perm = PermutationImportance(clf.best_estimator_).fit(X_train_df,Y_train_df)\n",
        "eli5.show_weights(perm, feature_names = X_train_df.columns.tolist())\n",
        "\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1342: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best parameters found:\n",
            "\n",
            "{'alpha': 0.0001, 'hidden_layer_sizes': (100,)}\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "    table.eli5-weights tr:hover {\n",
              "        filter: brightness(85%);\n",
              "    }\n",
              "</style>\n",
              "\n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
              "    <thead>\n",
              "    <tr style=\"border: none;\">\n",
              "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
              "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
              "    </tr>\n",
              "    </thead>\n",
              "    <tbody>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.2460\n",
              "                \n",
              "                    &plusmn; 0.0298\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                NSolutions\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 91.73%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0697\n",
              "                \n",
              "                    &plusmn; 0.0176\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                QualitativeDivergence\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 91.78%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0691\n",
              "                \n",
              "                    &plusmn; 0.0232\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                avg_gold_dum_pri_count\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 93.19%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0528\n",
              "                \n",
              "                    &plusmn; 0.0343\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                high_std_experience_dum\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 93.96%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0444\n",
              "                \n",
              "                    &plusmn; 0.0094\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                std_gold_dum_pri_count\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 94.51%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0388\n",
              "                \n",
              "                    &plusmn; 0.0109\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                avg_experience\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 94.86%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0353\n",
              "                \n",
              "                    &plusmn; 0.0099\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                std_experience\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 94.88%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0351\n",
              "                \n",
              "                    &plusmn; 0.0087\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                convergence_var\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 97.41%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0133\n",
              "                \n",
              "                    &plusmn; 0.0073\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                NumScoredSubmissions\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 97.59%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0120\n",
              "                \n",
              "                    &plusmn; 0.0097\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                skew_experience\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 97.75%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0108\n",
              "                \n",
              "                    &plusmn; 0.0070\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                GroupSize\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.18%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0080\n",
              "                \n",
              "                    &plusmn; 0.0025\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                skew_gold_dum_pri_count\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(120, 100.00%, 98.41%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0.0066\n",
              "                \n",
              "                    &plusmn; 0.0069\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                ComplexConvergenceDum\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "        <tr style=\"background-color: hsl(0, 100.00%, 100.00%); border: none;\">\n",
              "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
              "                0\n",
              "                \n",
              "                    &plusmn; 0.0000\n",
              "                \n",
              "            </td>\n",
              "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
              "                GroupDum\n",
              "            </td>\n",
              "        </tr>\n",
              "    \n",
              "    \n",
              "    </tbody>\n",
              "</table>\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "    \n",
              "\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANEMg0blSqUa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "bd016b38-e024-47da-9480-dc2d15f0ad9e"
      },
      "source": [
        "num_required_features = int(input(\"How many variables do you want to select? \"))\n",
        "req_feature_list = [] \n",
        "print(\"\\n\")\n",
        "for i in range (0,num_required_features):\n",
        "  feature_choice = input(\"Enter required feature: \")\n",
        "  req_feature_list.append(feature_choice) \n",
        "   "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "How many variables do you want to select? 4\n",
            "\n",
            "\n",
            "Enter required feature: ComplexConvergenceDum\n",
            "Enter required feature: NSolutions\n",
            "Enter required feature: QualitativeDivergence\n",
            "Enter required feature: avg_gold_dum_pri_count\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87bDVEcWOOLD",
        "colab_type": "text"
      },
      "source": [
        "2.2 Creating modified dataframe with only the required features the user has selected"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbOlSrk2oxAV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "3d7b49c6-ba63-431a-bd8a-33628681df7a"
      },
      "source": [
        "req_feature_df = pd.DataFrame(req_feature_list)\n",
        "col_names = list(X_train_df.columns)\n",
        "\n",
        "X_train_selected_features_df= X_train_df.copy(deep=True)\n",
        "for col_name in col_names:\n",
        "    if col_name not in req_feature_list:\n",
        "        X_train_selected_features_df = X_train_selected_features_df.drop(columns=col_name,inplace=False)\n",
        "\n",
        "X_train_selected_features_df"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ComplexConvergenceDum</th>\n",
              "      <th>NSolutions</th>\n",
              "      <th>QualitativeDivergence</th>\n",
              "      <th>avg_gold_dum_pri_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>32</td>\n",
              "      <td>0.115516</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>1.298079</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>0</td>\n",
              "      <td>271</td>\n",
              "      <td>0.027853</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>0.044433</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0.349953</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57735</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57796</th>\n",
              "      <td>0</td>\n",
              "      <td>77</td>\n",
              "      <td>0.728924</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57843</th>\n",
              "      <td>0</td>\n",
              "      <td>68</td>\n",
              "      <td>0.096943</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57864</th>\n",
              "      <td>0</td>\n",
              "      <td>22</td>\n",
              "      <td>0.385915</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57876</th>\n",
              "      <td>0</td>\n",
              "      <td>24</td>\n",
              "      <td>2.441815</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1739 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       ComplexConvergenceDum  ...  avg_gold_dum_pri_count\n",
              "10                         0  ...                     0.0\n",
              "23                         0  ...                     0.0\n",
              "66                         0  ...                     4.0\n",
              "103                        0  ...                     0.0\n",
              "188                        0  ...                     0.0\n",
              "...                      ...  ...                     ...\n",
              "57735                      0  ...                     0.0\n",
              "57796                      0  ...                     0.0\n",
              "57843                      0  ...                     0.0\n",
              "57864                      0  ...                     0.0\n",
              "57876                      0  ...                     0.0\n",
              "\n",
              "[1739 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0lHlAfaUxeS",
        "colab_type": "text"
      },
      "source": [
        "2.3 Creating all terms of a polynomial of degree specified by the user"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmgrgo1SUOpZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "af10a285-d20f-4d94-af3a-03c23f852329"
      },
      "source": [
        "polynomial_degree = int(input(\"Enter maximum degree of required polynomial: \"))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter maximum degree of required polynomial: 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uUbH3JwudfF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "outputId": "10a0f4dc-04b7-4472-cce0-218791b3529d"
      },
      "source": [
        "#creating new dataframe with all possibile polynomial terms \n",
        "\n",
        "selected_feature_df = pd.DataFrame(X_train_selected_features_df.columns)\n",
        "cols = selected_feature_df.columns.tolist()\n",
        "def PolynomialFeatureNames(sklearn_feature_name_output, df):\n",
        "  import re \n",
        "  cols = df.columns.tolist()\n",
        "  feat_map = {'x'+str(num):cat for num, cat in enumerate(cols)}\n",
        "  feat_string = ','.join(sklearn_feature_name_output)\n",
        "  for k,v in feat_map.items():\n",
        "    feat_string = re.sub(fr\"\\b{k}\\b\",v,feat_string)\n",
        "  return feat_string.replace(\" \",\" x \").split(',')  \n",
        "\n",
        "interaction = pp.PolynomialFeatures(polynomial_degree)\n",
        "X_inter = interaction.fit_transform(X_train_selected_features_df)\n",
        "names = PolynomialFeatureNames(interaction.get_feature_names(),X_train_selected_features_df)\n",
        "\n",
        "X_inter_df = pd.DataFrame(X_inter,columns= names)\n",
        "X_inter_df"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>ComplexConvergenceDum</th>\n",
              "      <th>NSolutions</th>\n",
              "      <th>QualitativeDivergence</th>\n",
              "      <th>avg_gold_dum_pri_count</th>\n",
              "      <th>ComplexConvergenceDum^2</th>\n",
              "      <th>ComplexConvergenceDum x NSolutions</th>\n",
              "      <th>ComplexConvergenceDum x QualitativeDivergence</th>\n",
              "      <th>ComplexConvergenceDum x avg_gold_dum_pri_count</th>\n",
              "      <th>NSolutions^2</th>\n",
              "      <th>NSolutions x QualitativeDivergence</th>\n",
              "      <th>NSolutions x avg_gold_dum_pri_count</th>\n",
              "      <th>QualitativeDivergence^2</th>\n",
              "      <th>QualitativeDivergence x avg_gold_dum_pri_count</th>\n",
              "      <th>avg_gold_dum_pri_count^2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>0.115516</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>3.696509</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.013344</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1.298079</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>225.0</td>\n",
              "      <td>19.471191</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.685010</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>271.0</td>\n",
              "      <td>0.027853</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>73441.0</td>\n",
              "      <td>7.548205</td>\n",
              "      <td>1084.0</td>\n",
              "      <td>0.000776</td>\n",
              "      <td>0.111413</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0.044433</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>576.0</td>\n",
              "      <td>1.066390</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001974</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.349953</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>2.099715</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.122467</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1734</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1735</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>0.728924</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5929.0</td>\n",
              "      <td>56.127144</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.531330</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1736</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>0.096943</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4624.0</td>\n",
              "      <td>6.592124</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.009398</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1737</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>22.0</td>\n",
              "      <td>0.385915</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>484.0</td>\n",
              "      <td>8.490119</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.148930</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1738</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>2.441815</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>576.0</td>\n",
              "      <td>58.603566</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.962462</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1739 rows × 15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        1  ...  avg_gold_dum_pri_count^2\n",
              "0     1.0  ...                       0.0\n",
              "1     1.0  ...                       0.0\n",
              "2     1.0  ...                      16.0\n",
              "3     1.0  ...                       0.0\n",
              "4     1.0  ...                       0.0\n",
              "...   ...  ...                       ...\n",
              "1734  1.0  ...                       0.0\n",
              "1735  1.0  ...                       0.0\n",
              "1736  1.0  ...                       0.0\n",
              "1737  1.0  ...                       0.0\n",
              "1738  1.0  ...                       0.0\n",
              "\n",
              "[1739 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HO9nko56WOzo",
        "colab_type": "text"
      },
      "source": [
        "**Stage 3: Selecting important polynomial terms** \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnXRTOZdm6gl",
        "colab_type": "text"
      },
      "source": [
        "Stage 3.1 Using K-fold cross validation to find best regularization parameter of the lasso model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuH57Bzi8BkB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "outputId": "9b639b46-5927-4005-b6b7-84dc18827020"
      },
      "source": [
        "lasso = Lasso()\n",
        "parameters = {'alpha': [1e-15, 1e-10, 1e-8, 1e-4, 1e-3, 1e-2, 1, 5, 10, 20]}\n",
        "\n",
        "lasso_regressor = GridSearchCV(lasso, parameters, scoring = 'neg_mean_squared_error', cv = 5)\n",
        "lasso_regressor.fit(X_inter_df,Y_train_df)\n",
        "\n",
        "print(\"Best parameter value is:\", lasso_regressor.best_params_)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 204.2560068435523, tolerance: 0.04611214917020441\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 194.1325230806634, tolerance: 0.04536885143467134\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 176.04295591213042, tolerance: 0.041248792791679346\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 207.4948309528312, tolerance: 0.04681167396543495\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 186.66042303744123, tolerance: 0.04298917704236118\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 201.3879444535623, tolerance: 0.04611214917020441\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 193.91461238323973, tolerance: 0.04536885143467134\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 173.7102626405582, tolerance: 0.041248792791679346\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 204.75549736446658, tolerance: 0.04681167396543495\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 185.93463797874227, tolerance: 0.04298917704236118\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 201.38795653243275, tolerance: 0.04611214917020441\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 193.91462931673698, tolerance: 0.04536885143467134\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 173.7102814143556, tolerance: 0.041248792791679346\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 204.75551545839647, tolerance: 0.04681167396543495\n",
            "  positive)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 185.93465372600264, tolerance: 0.04298917704236118\n",
            "  positive)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best parameter value is: {'alpha': 0.01}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbXIQOXZpH0D",
        "colab_type": "text"
      },
      "source": [
        "Stage 3.2 Displaying the coeffecients of each polynomial term, and the user selects what terms to keep. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qndgHOLDBE9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "c6ffcab5-3294-4a98-c8b9-a7afc2cd7346"
      },
      "source": [
        "#coeffiecients when lasso with the best hyper parameter is fitted\n",
        "coefficients = list(lasso_regressor.best_estimator_.coef_)\n",
        "feature_coefficients = [(name, round(coefficient, 20)) for name, coefficient in zip(names, coefficients)]\n",
        "\n",
        "#sorting the coefficients in descending order\n",
        "feature_coefficients = sorted(feature_coefficients, key = lambda x: x[1], reverse = True)\n",
        "\n",
        "print(\"The coefficient of each feature in the polynomial is: \\n\")\n",
        "feature_coefficients"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The coefficient of each feature in the polynomial is: \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('QualitativeDivergence', 0.11102623677097967),\n",
              " ('NSolutions', 0.0040267211825008396),\n",
              " ('avg_gold_dum_pri_count^2', 0.001157453053928741),\n",
              " ('NSolutions x QualitativeDivergence', 0.0011010536798848902),\n",
              " ('1', 0.0),\n",
              " ('ComplexConvergenceDum', 0.0),\n",
              " ('avg_gold_dum_pri_count', 0.0),\n",
              " ('ComplexConvergenceDum^2', 0.0),\n",
              " ('ComplexConvergenceDum x QualitativeDivergence', -0.0),\n",
              " ('ComplexConvergenceDum x avg_gold_dum_pri_count', -0.0),\n",
              " ('QualitativeDivergence x avg_gold_dum_pri_count', 0.0),\n",
              " ('NSolutions^2', -8.77954739410998e-06),\n",
              " ('NSolutions x avg_gold_dum_pri_count', -6.697921464788887e-05),\n",
              " ('ComplexConvergenceDum x NSolutions', -0.0004109132896667968),\n",
              " ('QualitativeDivergence^2', -0.017728228228042053)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIRrHZOh9GZK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "9b6e6a1f-a7ad-4178-eee8-9082f493cddf"
      },
      "source": [
        "print(\"A higher coefficient indicates higher importance of a term.\\n\")\n",
        "num_required_terms = int(input(\"How many terms of the polynomial do you want to select? \"))\n",
        "req_term_list = [] \n",
        "for j in range (0,num_required_terms):\n",
        "  term_choice = input(\"Enter required term name: \")\n",
        "  req_term_list.append(term_choice)\n",
        "req_term_df = pd.DataFrame(req_term_list)\n",
        "col_names_new = list(X_inter_df.columns)\n",
        "\n",
        "X_train_selected_terms_df = X_inter_df.copy(deep = True)\n",
        "for col_name_new in col_names_new:\n",
        "    if col_name_new not in req_term_list:\n",
        "        X_train_selected_terms_df = X_train_selected_terms_df.drop(columns=col_name_new,inplace=False)\n",
        "\n",
        "X_train_selected_terms_df\n",
        "print(\"The predicted polynomial is:\\n\")\n",
        "for h in range (0,num_required_terms):\n",
        "  print(req_term_list[h])\n",
        "  if h != num_required_terms-1:\n",
        "    print(\"+\")\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A higher coefficient indicates higher importance of a term.\n",
            "\n",
            "How many terms of the polynomial do you want to select? 4\n",
            "Enter required term name: QualitativeDivergence\n",
            "Enter required term name: NSolutions\n",
            "Enter required term name: avg_gold_dum_pri_count^2\n",
            "Enter required term name: NSolutions x QualitativeDivergence\n",
            "The predicted polynomial is:\n",
            "\n",
            "QualitativeDivergence\n",
            "+\n",
            "NSolutions\n",
            "+\n",
            "avg_gold_dum_pri_count^2\n",
            "+\n",
            "NSolutions x QualitativeDivergence\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIRjRaPPvNo_",
        "colab_type": "text"
      },
      "source": [
        "**Stage 4: Creating the final polynomial**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyVTmhCnPTsY",
        "colab_type": "text"
      },
      "source": [
        "4.1 Fitting a OLS linear regression method with the shortlisted terms through different subsamples of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPr0Fv3f60Ix",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "55a41a3c-530d-476b-eeec-e7e1ae0d6d2a"
      },
      "source": [
        "k = int(input(\"Enter number of sub-samples\"))\n",
        "coeff_array = np.ones((k,(len(df_filled.columns)-1)))\n",
        "\n",
        "for g in range (0,k):\n",
        "  sub_sample_data = df_filled.sample(n=int((len(X_train_df))/k ))\n",
        "  X_sub_sample_df = sub_sample_data.copy(deep=True)\n",
        "  selected_columns = X_sub_sample_df[[target_name]]\n",
        "  Y_sub_sample_df = selected_columns.copy()\n",
        "  X_sub_sample_df = X_sub_sample_df.drop(columns=target_name)\n",
        "  reg = LinearRegression().fit(X_sub_sample_df, Y_sub_sample_df)\n",
        "  coeff_test =np.array(reg.coef_)\n",
        "  for f in range (0,(len(df_filled.columns)-1)):\n",
        "    coeff_array[g][f] = coeff_test[0][f]\n",
        "coeff_array_transpose = coeff_array.transpose()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter number of sub-samples5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N14ildvYQmBS",
        "colab_type": "text"
      },
      "source": [
        "4.2 Running an OLS on different sub-samples of the data, and respresenting using heatmap "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RgTzSB49JuZ0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_label = X_train_df.columns.to_list()\n",
        "x_label = []\n",
        "for r in range (0,k):\n",
        "  s = \"SubSample\" + str(k)\n",
        "  x_label.append(s)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVebUAxmEWGE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "outputId": "6bb2b331-c990-4f5e-c86b-b97551bb9aad"
      },
      "source": [
        "sns.heatmap(coeff_array_transpose, cmap=\"YlGnBu\",yticklabels=y_label,xticklabels=x_label)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f41b986d390>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAEtCAYAAAAyfqiGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd7xU1dW/n+8FbNiJMZYo2GJFBER9LbGgwcTYFY1RMUY0scbXJCb29kZj/Nkw1lhiQRQbUSwIYiEqoCiIXcRu7KhRUHD9/thr4DDMzJ3LnXunsB4+53PP7LPL2jPDrLPLWV+ZGUEQBEEQ1A5N1TYgCIIgCIK5CeccBEEQBDVGOOcgCIIgqDHCOQdBEARBjRHOOQiCIAhqjHDOQRAEQVBjdKy2AUHjsP61jzbcc3kr/KAx71/v+8lS1Tah4rw8bWq1TWgT1ll6rWqb0EaspdbWsOgq+5b9m/P1m4Nb3V57Es45CIIgqEukxrx5hnDOQRAEQZ2iBl6ZDeccBEEQ1CWNPHIuq2eSfiDpZkmvSXpK0nBJbbIQImlrSXe3ovwBkp6TNEnSBEnHVdK+ekDSaEkvSZoo6UVJgyQtXW27giAIKonUVPZRbzRrsSQBdwCjzWx1M+sF/AlYvq2NaymSdgSOAXYwsw2ATYFpVbCjFmYk9jOz7kB3YAZwV5XtCYIgqChSh7KPeqOc24ltgG/N7LJcgpk9Czwm6dzMKLU/zB75PizpLklTJJ0taT9JYz3f6p7vWkmXSRov6WVJO+U3LKmzpKu97ARJu3j6hZJO9vOfSHpE6dboT8BxZvau2znDzK70fD0kPeGjyTskLePpoyWd4228LGlLT39C0noZW0ZL6l3CpgGShkkaBYyUtJikWyQ97+09Kam3591B0uOSnpZ0q6TFPX2qpNM8fZKktT19cUnXeNpESXuUqieLmX0D/AFYRdKGkrpKei7Tr+MknZrp4/n+mbwgaWNJt0t6RdKZZXxXgiAI2o0FeuQMrA88VSB9d6AHsCHQFzhX0gp+bUPgMGAdYH9gLTPrA1wFHJmpoyvQB/gZcJmkRfLaOAEY5WW38TY6k5xwf0nbABcBB5nZdyVsBfgn8EcfTU4CTslc6+htHJNJHwLsDeD9WsHMxpewCaAnsKeZ/Rj4LfCpma0LnAT08rq+B5wI9DWznsB44NiMLR95+qVAbkr+JGCamW3g9o8qo57ZmNks4Flg7SLvTZZvzKw3cBlptH046X0dIKlLGeWDIAjahQXdORdjC2Cwmc0ys/8ADwMb+7VxZvaemc0AXgMe8PRJJIec4xYz+87MXgGmMK/z2AE4XtIzwGhgEWAVM/sKOAQYAQwys9dKGSppKWBpM3vYk64Dtspkud3/PpWx7xZgTz/fGxhayia/NsLMPvHzLYCbAczsOWCip28KrAuM8ToOBFZtxpa+wCW5DGb2aRn1zPM2lLiWZZj/nQRMznyOU4AfzlOpNNBH2uM/GT0s/3IQBEGbIZrKPuqNctZGJzPHSZXLjMz5d5nX3+W1mf8Aef5rAXuY2UsF2tgA+BhYMc/WXsCo+bR3Vs4+M3tH0seSugP9STMBRW2StAnw3zLaEsmJ71uuLfNZT9a2DqT36wVgJnPflOXPVmQ/q/zPcR57zOwK4ApozCAkQRDULvU4Ii6Xcno2ClhY0sBcgjusz0hTyx0kLUcaiY5tYft7SWrydejVgHwnfD9wpG9KQ9JG/ndV4H+BjYAd3TEC/IU0zfwDz7eQpF+b2TTg09x6Mmmq/WGaZwhpvXYpM8uNfAvaVIAxzJkWX5fkHAGeADaXtIZf66zmd76PIE0v42WWKbceSZ1I78tb3of/AN+X1EXSwsA8a/1BEAT1wAI9rW1mBuwG9FV6lGoy6cf+JtJU7bMkB/4HM3u/he2/SXLo9wKHmdn0vOtnAJ2Aid7uGe4U/8GcjV8HA1dJWsTMhgODgAc9/9PAkl7XgSTHPZG0Vn56GfYNBfYhTXEXtalI2b8Dy0l6HjiTNKqfZmYfAgOAwW7L4zS/FnwmsIzS5rtngW3KqOdGT38O6AzsAmBm33rfx5Kc/ovNvQlBEAS1SJM6lH3UG0q+twoNS9cCd5vZ0Oby1iM+ldzJzKb7zMCDwI9893RD0ojT2hFbu36I2Nr1Rutja39/7f8t+zfngxfPi9jaAQCLAQ/5tLKA3zayYw6CIGhv6nG6ulyq5pzNbEC12m4PzOwLoHe17QiCIGhUwjkHQRmcvFU5m9WDWuC217+otgltQGP+nE36ZEq1TWgT9l6tEtP14ZyDIAiCoKZoampcF9a4PQuCIAgamnoMLlIu4ZyDIAiCuqSR15wbt2c1giSTdF7mdVZo4kcuNvGMC01c0UxdzcppSlpa0m8zr1eU1JCPqwVBsGAjqeyjjLr6KUntvirp+ALXj1USMpooaaQHw8pdm+W/489Iqkgc43DObc8MYHcXqsjnIuB8M+thZusAF1egvaVJohsAmNm7ZtbS8KtBEAQ1T6UihHlcikuAHUmaBft6ZMcsE4DeLj40FPhr5trX/jvew8x2rkTfwjm3PTNJsad/V+DaCsDbuRdmNglA0iKaIxE5wdW35kLSqZKOy7x+TlJX4Gxgdb+DO1cZichi9SrJXd4u6T4leci/enoHJWnPnCxooT4EQRBUhQoKX/QBXjWzKR6P4mY8qmIOM3vIRZcghU9eueIdyhBrzu3DJaRwn3/NSz+fJP/4b5Jy1zVm9hkpjraZ2QZKms4PlBF/O8fxwPpm1gPAHXaOUvX2IMUqnwG8JOli4PvASma2vte1dIt6HQRB0Ia0ZLe260MMzCRd4cI9ACsBb2WuvQ1sQnEOJoWdzrGIpPGkwdjZZnZn2YYVIUbO7YCZfU7Skz4qL/0akub1rcDWwBMuRrEFcIPneRF4A6jEQ4Gl6h1pZtM8vvnzJPnJKcBqki6W1A/4PL9CZSQjHxw8vAImBkEQlEdLRs5mdoWZ9c4cJff4FG1T+iUpwNS5meRVzaw38AvgAg/Z3CrCObcfF5DutjpnE31N+Goz24V017V+mfU1J/3YUrLykLOAjq4bvSFJt/ow4Kr8QtkvfN99f9pKE4IgCFqAmso/SvMOc+vVr+xpczcn9QVOAHZ2nXsgSQz73ymk38tiaoVlE865nTCzT0jqVgfn0nx3YCc//wHQhfSFeBTYz9PXAlZhXjnNqUBPz9MT6ObpXwBLFDGjnHpn45vYmszsNuDEXHtBEAS1QAUlI8cBa0rqJmkhkhrhXLuuleSBLyc55g8y6cv4jGfuN3Nz0uxjq4g15/blPOCIzOsdgAsl5aQyf29m70v6O3CppEmkEfIAM5uR9zjAbcABLlv5JPAygJl9LGmMbwK7l7TenaOcerOsBFyjOd/sP81ft4MgCCpPOY9IlYOZzZR0BHA/0AG42swmSzodGG9mw0jT2IsDt3q7b/rO7HWAyyV9Rxrwnm1mrXbOVZOMDBqPW6bcF1+mIAjKYu/V+rXas67Z++Kyf3NeGX9kSEYGQRAEQVujpg7VNqHNCOccBEEQ1CcNvGsqnHNQMbotMavaJlScj2c05v/+yZ823n/9jbp8W20T2oQrXlq82ia0CXuvVoFKKrTmXIs03v/QIAiCYMEgnHMQBEEQ1BiNObEFhHMOgiAI6hRripFzEARBENQWDeycG3hSoPaQtLykmyRNkfSUpMcl7dbGbe7kClTPuhbpoZ5+mKQD2rLtIAiCNkUq/6gzYuTcTiiFlLkTuM7MfuFpqwI75+XraGYzK9RmJ5JcZR8ze9tDzHUFMLPLKtFGEARB1ag/n1s24Zzbj22Bb7JO0czeAC6WNADYnRQaroOPpq8GVgO+Agaa2URJpwJfmtnfIGk4Azt5dfcBT5HiX08GDiCJYXQEPvb2ZuCxtHN1ATcBWTmpDTLtXkaKvw1wjJmNqcxbEQRBUAFiWjuoAOsBT5e43hPY08x+DJwGTDCz7sCfSXKTzfEj4O9mtg5J2vG3LrYxDHhD0mBJ+ykvAryrYvVw/ecrgdv8puFC4Hwz2xjYgwKKVEEQBFWlgae1wzlXCUmX+DrwOE8a4c4Uku7y9QBmNgroImnJZqp8KzOyvcHrwMx+DWwHjAWOI43IC9mzOXAI8CtP6gsMkvQMycEvKWmeaAhZPec7/nlfs/0OgiCoGB1U/lFnxLR2+zGZNAIFwMwOd3mx8Z703zLqKKXhnB8AfvZrM5sETJJ0PfA6MCCbUdIKwD9IUmhfenITsKmZTacELlh+BcC4D+8J4YsgCNqP+vO5ZRMj5/ZjFLCIpN9k0hYrkjeru7w18JGZfU5xDWeAVSRt5ue/AB6TtLiXz9EDeCPbkG8auxX4o5m9nLn0AHBkJl+P5rsYBEHQfphU9lFvhHNuJyxpc+4K/FjS65LGAtcBfyyQ/VSgl6SJwNnAgZ5+G7CsazgfgWs4Oy8Bh0t6AVgGuJR0X/kHSS/59PRp5I2agf8BegOnSXrGjxWBo4DekiZKeh44rHXvQBAEQYVpUvlHnRHT2u2Imb0H7FPk8rWZfJ+QHHl++a+BHfLTJXUFZprZLwvU+9MitpyaeblIoTxA/yLpQRAE1af+fG7ZhHMOgiAI6pM6nK4ul5jWbgDMbKqZrV9tO4IgCNqVCu7WltTPlwBflXR8gevHepTFiZJGehCp3LUDJb3ix4H5ZeeHGDkHFWOvyzpV24SKYx0b8/61y6oLV9uEinPp543XJ4Aea1XbghqmQiNnSR2AS4DtgbeBcZKGmdnzmWwTgN5m9pVv7P0r0F/SssAppL07BjzlZT9tjU2N+csTBEEQND6VC0LSB3jVzKaY2TfAzcAu2Qxm9pCZfeUvnwBW9vOf4HEq3CGPAPq1tmvhnIMgCIL6pKn8IxswyY+BmZpWAt7KvH7b04pxMHDvfJYti5jWDoIgCOqTFkxrZwMmta5J/ZI0hf3j1tZVihg5B0EQBHWJdVDZRzO8A/ww83plT5sLSX2BE0jRFGe0pGxLqZpzlrSypLt8d9sUSYNc0nB+6hotqbefD5e0tB+/LaPsXPkkrShp6HzasbWkaa6f/JKkRyTtlLkeGspBEASVonJrzuOANSV1k7QQKR7FsLmb0kbA5STH/EHm0v3ADpKWkbQMKRbF/a3tWlWcs2sb3w7caWZrAmsCi5J2v7UKM/upmX0GLA0065zz87lK056tMOFRM9vIzH5EirI1SNJ2XvdlZlaOwlRJJMVyRBAEgVpwlMDMZpKiLt4PvADcYmaTJZ0uaWfPdi5J1vdWj6Q4zMt+ApxBcvDjgNMzIkbzTbVGztsC083sGgAzmwX8DjhA0hGSBuUySro7Fx9a0qW+kD9Z0mmFKpY01QUlzgZW9zfxXI8zPVLS05ImScrtxMvP19V1kpH0hKT1MnWPltRbUmdJV0sa66PkXea1BMzsGeB00oeOpFMlHSdpbQ/fmau3q6RJft5L0sOSnpJ0v4tS5Nq+QNJ44GhJG/vzdjm7czZ38Nfj/Pqhnr611zFU0ouSbvSbJLyufyupZI2VtESxeoIgCGqGCobvNLPhZraWma1uZmd52slmlnPCfc1s+ZzErpntnCl7tZmt4cc1FelaJSqZD9YDnsomZIQdSo0KTzCz3kB3Uozq7iXyHg+85m/i74HpwG5m1hPYBjjPnVN+vixDgL1htnLTCmY2nrTmMMrM+nhd50rqXMSOp4G18/r6IrCQpJxwRX9giJIIxcUkXedeJHnHszJFFzKz3mZ2HnANcKjrMM/K5DkYmOY6zBsDh2Ta2Qg4BlgXWA3Y3KdwhgBHm9mGJKnIr5upZzbZHZBfjB9e5C0IgiBoA0LPuWbYW9LTpIfB1yM5mXIR8H9KYhIPkra6L99MmVuA3BT33kBuLXoH4HglMYnRpNjUq5Rot1jdudjV/UkO8kfA+sAIr/tE5jxLh+dB0tLAEmb2uKfflMmzA2kG4hngSaALadkAYKyZvW1m3wHPAF29zffMbBykmySf4ilVz2zM7Aq/Yei9RO+CYbyDIAjahgpNa9ci1Vq7fJ45Tg8ASUsCPwA+BrIxcRbx692A44CNzexTSddSXLChEPsBywG9zOxbSVObK29m70j62Efo/ZmjzCRgDzN7Ka8PhZz9RqQ1jHyGkNYubk9N2SuSNgAmm9lmBfJDeZrPAo40s7k2JPjSwIxM0ixKf/4F6wmCIKgZGjSCH1Rv5DwSWCy3c1kpdNp5wCDgdaCHpCZJPyRFbgFYkuScprkT3LGZNr4Alsi8Xgr4wB3zNsCqRfLlMwT4A7CUmU30tPuBIzNrthsVKuhO/SRSWLi5MLPXSA7yJG8DkuzjcnJdZkmdsmvembKfAV9I2sSTskpX9wO/8SlyJK1VYso91+YKkjb2/Ev4hrOW1hMEQdCumMo/6o2qjJzNzCTtBlwi6STSiHaImZ3lDu910uj6BdKaLWb2rKQJwIukaCxjmmnjY0ljfKPUvcA5wL9849V4r6dQvnxHOhS4kLQbL8cZwAXARElNbm/ukakt3c7FgA+Ao8xsZBEzh5B2AHZzW76RtCdwkaSlSJ/PBcDkAmUPBq6U9B3wMDDN068iTVc/7e/lhxSQn8y8T99I6g9cLGlR0npz35bWEwRB0O7UoU5zucjMqm0Dkv4HGEzasPV0te2pByQtbmZf+vnxpM1qR1fTpq5nPFD9L1OFCeGL+uHzzxvu6wc0rvDF0G23arVnXe3Q28r+0KdcvkddefKaeF7WzP7NnGnmoDx+JulPpM/wDWBAdc0JgiBoZxp45FwTzjloOWY2hDlr1TXBkEO/rbYJbUIj/v9fuMP0apvQJjTiZzX8rcab5agYjTmxBYRzDoKSNOKPfaMSn9UCSIfG9c7hnIMgCIK6xOowuEi5hHMOgiAI6pPGHTiHcw6CIAjqlAZeywjnHARBENQnDTyt3cCTAq1D0jGSFitybYAyylnVRq3QoA6CIKhbOqj8o84I51ycY0hRvmoaSR0roEEdBEFQd1iTyj7qjXDOgJI+8z2uZ/ycpFOAFYGHJD3keQ6S9LKSDvPmzdS3nKTbXAt5nKTNPf2uTDzxQyXd6OejJV2opM38nKQ+Gbvm0Y32kfswSaOAkZpbgzr0nIMgWDCooJ5zrRFrzol+wLtm9jMAj2t9ELCNmX2kpOV8GtCLFMP6IZJsZTEuBM43s8ckrUISkVgHGAiMkfQ68L/Appkyi5lZD0lbkXSc12eObvSvlGQix0p60PP3BLqb2SeSumbqma3DLGlhb+8Bv7YRSWrzXVJs8s39ZmMI0N/Mximpg31drB4zez3bUUkDvV8cf+4R7HpAvxJvSxAEQQVp4DXncM6JScB5ks4B7jazRzX3h74JMNrMPgSQNIS5ZS3z6Qusm6ljSY+F/R9JJ5Oc+25m9kmmzGAAM3tE0pLujHcAdpZ0nOfJ6kaPyCufYweguwtoQFLjWhP4Btdz9j7k9Jynkafn7NeL1TOXczazK4ArAJ784J7GDG4cBEFtUsG5X0n9SAOrDsBVZnZ23vWtSEJE3YF9zGxo5toskh8BeNPMdm6tPeGcATN7WVJP4KfAmZKKqUiVSxOwqZkVipG4AUmzesV8Mwq8LqYbvQnFtZ1DzzkIggWDCo2clWSLLwG2B94GxkkaZmbPZ7K9SdIwOG7eGvjazHpUxBgn1pxJu52Br8zsBpKEY0/m1nl+EvixpC5K+sZ7NVPlA8CRmfp7+N8+JB3qjYDjJHXLlOnvebYgTSdPo0zd6DxCzzkIggWDjk3lH6XpA7xqZlPM7BvgZmCXbAYzm2pmE4Hv2qYzcxMj58QGwLlK2sjfAr8BNgPuk/SumW0j6VTgceAz4Jlm6juKpFU9kfQePyLpaOBK4CAze1fS/wJXS9rWy0xX0oHuBPzK00rpRhcj9JyDIFggaEn4zuz+GOcKX5YDWAl4K3PtbdJyZrksImk8MBM428zubEHZgtSEnvOCjqTRwHFmNr7atrSGRlxzrsNNnmWxcIeG+6ga9rNqVFWqP3TfvtWf2Kr/N6LsL/Ibfy7enu+t6Wdmv/bX+wObmNkRBfJeS9qblF1zXsnM3pG0GjAK2M7MXiu/J/MS09pBEARBfSKVf5TmHeCHmdcre1pZmNk7/ncKMJq0dNkqYlq7FUg6gXnXn281s7NaUo+ZbV0xo6rIB9Mb717v/ncWqbYJbUJHNd7IefuVZjSfqQ7ZaZXG7FdFqNx0yThgTd8H9A6wD/CLcgpKWoa0Z2mGpO+R4mD8tbUGhXNuBe6EW+SIgyAIggpRIedsZjMlHUHaCNsBuNrMJks6HRhvZsN80+wdwDLAzyWdZmbrkWJYXO57lppIa87PF2mqbMI5B0EQBHWJVTBmtpkNB4bnpZ2cOR9Hmu7OL/dv0qbiihLOOQiCIKhPIkJYEARBENQYjbpFn3DOQRAEQb3SuL55wXyUStJU31XXMEi6StK61bYjCIKgvWhqKv+oN2Lk3ABI6pB7eD4IgmBBoR6dbrk0cNcSmleruX/m2qKS7pV0iIprJ98jqbufT3BVKSSdLumQEu3+PqOFfJqn7SZppBIrKOlD/0BJn/kuJb3lV5T0pHP1/NJtekbS5R6gHUlfSjpP0rPAZl62t1/bQdLjkp6WdKukxT19qqTTPH2SpLU9fXFJ13jaREl7lKonr58DJY2XNP6+m+5t5acVBEFQPpLKPuqNhnfOzNFq3tDM1gfu8/TFgX8Bg83sSuZoJ/cBtiHF2u4MPApsqaTxPJP0gDnAlsAjhRpUkltckxRMvQfQS9JWZnYH8B5wOCnO9ilm9r4X6wPsQZIj20tSb0nrkAQxNnfFk1nAfp6/M/Ck9+uxTNvfA04E+ppZT2A8cGzGvI88/VLmqKucRBLb2MDMugOjyqgHSJKRZtbbzHr3+8WOhd6OIAiCNqFyAcJqjwVhWruYVvNdwF/N7EbPV0w7+VGSkMXrwD3A9pIWA7rlSzlm2MGPCf56cZKzfoSkVvUc8ISZDc6UGWFmHwNIuh3YgnQz0IskXwawKPCB558F3Fag7U2BdYExXmYhkmBHjtv971PA7n7elxQRBwAz+1TSTs3UEwRBUFXq0emWS8M75xJazWOAfpJusqT+UUw7eSGgNzAFGAF8DziE5NyKIeAvZnZ5gWsrkyTHlpfUZGY5+bFies7XmdmfCtQz3cxmFWl7hJntW8S2XCzAcvScS9UTBEFQVdTAc78N3LWECms1A5wMfEoS2IYi2smu7fkWKYb246SR9HEUmdLO1PWrzFrvSpK+r6STfDWwL/ACc08Tby9pWSXZxl1JNw8jgT0lfd/rWVbSqs10+Qlgc0lreJnOktZqpswI0lQ7XmaZ+awnCIKg3Wjkae2Gd86ksGpjJT0DnAKcmbl2NLCopL+StJM7kbSTJ/vrHI8CH5jZ136+sv8tiJk9ANwEPC5pEjAUWAL4M/CorxEfC/za15UBxpKmqScCt5nZeI/PeiLwgJI29AhghVKdNbMPgQHAYC/zOLB2qTKk92QZ3zD3LLDNfNYTBEHQbnRoKv+oN0LPuQaQNADoXUg7tJ7415v3NtyXKVSp6odGVaXqtkSh1av6Z92ld2r1eHa9ax4p+4s8+aCt6mr83PBrzkEQBEFjUo+PSJVLOOdWIGkD4Pq85BlmtklL6jGza4FrK2RW1ejcsfFGYysvNrPaJrQJS3ZqvM+qUfkuPqqiNPKGsHDOrcDMJpGeYw6CIAjamQYeOIdzDoIgCOqTRg7fGc45CIIgqEsaWDFygXiUKgiCIGhAKvmcs6R+kl6S9Kqk4wtc38p1BmZK2jPv2oGui/CKpAMr0bdwzg2Ax+G+qNp2BEEQtCeVcs4uKHQJsCMpbPG+mleC901S7Ieb8souS4qhsQlJI+EUD+TUKmJau86R1NHMxpOEKYIgCBYYVLl57T7Aq2Y2BUDSzcAuwPO5DGY21a99l1f2J6RQx5/49REkwaXBtIIFeuQs6U5JT0ma7NKHh0k6N3N9gKRBfn6ST3k8JmlwRiCjUL2rS7rP635U0tqSOipJSG7tef4i6Sw/nyrpry7ZODYTMnM5Sbd5uXGSNvf0UyVdL2kMcL2krSXd7deKSV8OkHS72/WKR0XL2dvPp2uezcUeL1ZPEARBrdCSkbMy8rZ+DMxUtRIpTHOOtz2tHFpTtigL+sj5V2b2icezHgdsR4pp/Xu/3h84S9LGJDnHDUkhPp+mtPDFFcBhZvaKpE2Av5vZth4JbKikI0l3VtnnoaeZ2QaSDgAuAHYCLgTON7PHJK1CitmdC/e5LrCFmX2dc/hOTvryV5KWJoUufdCv9QA2IolfvCTpYmA6Sb5yKzN73adoitZjZv/NdtS/4AMBfnfOEez0y5CNDIKgfWjJbm0zu4L021wXLOjO+ShJu/n5D4FuwBRJmwKvkGJJjyHF4L7LzKYD0yX9q1iFSmIX/wPcmoleszCAmU2WdD1wN7CZi2rkGJz5e76f9wXWzdSzpNcPMMxjfedTTPoSYKSZTXM7nwdWBZYBHjGz193GT5qp54VsY9kv/Kh3h0e4hCAI2o0K7tZ+h+QDcqzsaeWW3Tqv7OjWGrTAOmcfbfYlOcmvJI0mOaCbgb2BF4E7zMxaGCKuCfjMzIoFJ9kA+Az4fl66FThvAjb1m4Ks7QBzjWCzlyksfbkJc+QioTzJyHnqCYIgqBUqGIRkHLCmpG4kZ7sP8Isyy94P/F9mE9gOQCGZ3xaxIK85LwV86o55bWBTT7+DtBFgX5KjhjR6/rmkRXzkulOxSs3sc+B1SXsBKLGhn+8OLAtsBVzs08U5+mf+Pu7nDwBH5jJIKicaWUHpyxI8AWzlX8rczsP5qScIgqBdUVP5RynMbCZwBOl37wXgFp/pPF3SzgCSNpb0Nkk++HIl9cLcbOMZJAc/Djg9MwM53yywI2fgPuAwSS8AL5GcFGb2qaeta2ZjPW2cpGEkOcf/AJOAaSXq3g+4VNKJpDXqmyW9A5wNbGdmb/lGswuB3DNxyyhJM84g3RgAHAVc4ukdSRrShzXTrzNIa9YTJTUBr1P6ZuJDXze+3fN/AGzf0nqCIAjam0qG7zSz4cDwvLSTM+fjSFPWhcpeDVxdOWtCMrJsJC1uZl9KWozkJAea2dMVqnsqSTLyo0rUV3IpuaUAACAASURBVC0acc157Iedqm1Cm9CIwherNqi04qqLN2a/1l+m9ZKRW/1rTNlf5Ed+vnldxRNbkEfOLeUKpYfSFwGuq5RjDoIgCOaPiK0dYGbzbA6QdAmweV7yhWZ2TQvr7toK02qGmY03GKNHl8aUjPw2P4xCAzDliw7VNqFN+O+3dTXgK5v1Wx1DK1SpgiKY2eHVtiEIgmBBpZGFL8I5B0EQBHVJOOcgCIIgqDGa1IBraU445yAIgqAu6Rgj52B+UFKMapgdRY3WnyAI6ptGHjk38Eb0hKQDJE10xaXrJXWVNMrTRrqgBJKulXSRpH9LmiIX05Z0s6SfZeq7VtKekjpIOtfVoiZKOtSvb62kRDUMeF5Sk6S/S3pR0ghJwzN195L0sJJ61f2SVvD00ZLOcUWolyVt6ekdJP1N0nPe5pGl6inwXqwtaWzmdVdJk/z8ZO/Lc5KuyEQGGy3pAknjSTHGgyAIaoImlX/UGw3tnCWtB5wIbGtmG5Kcy8Wk55S7AzcCF2WKrABsQYqEdbanDSHF2kbSQiTlqnuAg0lKUhsDGwOH5EJgAj2Bo81sLWB3oCtJRWp/YDOvq5PbsqeZ9SJFlzkrY0tHM+sDHEMS8oak/tQV6JGzv4x6ZmNmLwILZezs7/0DGGRmG5vZ+sCizB0NbCEz621m5xWqNwiCoBo0teCoN+rR5pawLXBrLvKWxzvdDLjJr19PcsY57jSz78zseWB5T7sX2EbSwsCOJAWnr0nBzQ+Q9AzwJNAFWNPLjM2pPHn9t3q97wMPefqPgPWBEV7HicwdGu52//sUySFDEuq4PDe17P1prp58bmHuON4557yNpCd9JL0tsF6mzBCKoIxG6vAb7i3RbBAEQWVp5JFzrDnPTVa1SQBmNl1JseonJGd2c+b6kWZ2f7YCJbWrYopRc2UFJpvZZs3YUo56VKl68hlCkrO8HTDXnF4E+DsphOhbkk4lRULLUbQ/WcnIB95pvPCdQRDULoo157plFLCXpC4wW3Hp3yQ5MEgCFY+WUc8Q4CBgS5JgBiT1kt/4tDKS1pLUuUDZMcAevva8PHN0P18ClpM0e5rbp+FLMQI4VFLHTH9aVI+ZvUZy+CcxZ0Scc8QfKalu7dmMHUEQBFWno8o/6o2GHjm75NdZwMOSZgETSBKM10j6PfAhyek2xwOkKfC7zOwbT7uKNN38tG+e+hDYtUDZ20jr1M8DbwFPk9aqv/GNYRdJWor0WVwATC5hx1XAWiSlqG+BK81s0HzUMwQ4F+gGYGafSboSeA54nyR7FgRBUNM08m7tUKVqBzKKVl2AscDmvv7cUDTitPZ3Voe33GXQiLG1p37ZmLG1l1+kAT8sYO/V+rX6P9cvH3647N+cG37847r6z9zQI+ca4m5JSwMLAWc0omMOgiBobxp5XTaccztgZlu3d5uVUswKgiCoVepxF3a5hHNuUEIxKwiCRqeSa86S+gEXAh2Aq8zs7LzrCwP/BHoBHwP9zWyqpK7AC6TNuQBPmNlhrbUnnHNQMU4Ys2S1Tag4+6zzdbVNaBMG3TCj+Ux1xnY/X7TaJrQJx67/ZbVNqFkqtQtbUgfgEmB74G1gnKRhHvMix8HAp2a2hqR9gHOYEzPiNTPrURlrEo08ZR8EQRA0ME2yso9m6AO8amZT/Imcm4Fd8vLsAlzn50OB7XJhjtuCcM5BEARBXdKSCGHZaIZ+DMxUtRLpUdccb3sahfJ4lMZppMiQAN0kTXCNgy0r0beY1g6CIAjqkpZsCMtGM6ww7wGrmNnHknoBd0paz8w+b02lMXIOgiAI6pIKCl+8A/ww83plTyuYx6M0LgV8bGYzzOxjADN7CniNFCyqVbSLc5Z0jKTFilwbIGlQBdvqKum5ItdGS+pdZj0VtWt+kbSipKFVbH9pSb+tVvtBEATF6NhkZR/NMA5YU1I3Vx/cBxiWl2cYcKCf7wmMMjOTtJxvKEPSaiQBpCmt7Vt7jZyPAQo656A4kjqa2btmVs1Y10sD4ZyDIKg5KjVy9jXkI0iaCS8At3j459Ml7ezZ/gF0kfQqcCxwvKdvRQqp/Axpo9hhrhjY6r5VFEmdJd0j6VlJz0k6BVgReEjSQ57nIEkvSxrLvIEy8utbXdITkiZJOlPSl54uSed6G5Mk9S9QdlFJN0t6QdIdJJ3iUm0VtEvStR6/Ovc6Z8PWvgHgLklTJJ0taT9JY92m1Uu0da2ky3xjwsuSdvL0AZKGSRoFjCw1E+D5O0j6m78PEyUd6enb+QaFSZKu9mf0kDRV0vf8vLeS4haSTvV8o70vR3kTZwOrS3pG0rml3r8gCIL2pJKSkWY23MzWMrPVzewsTzvZzIb5+XQz28vM1jCzPmY2xdNvM7P1zKyHmfU0s39Vom9tsSGsH/Cumf0MwMUYDgK2MbOPJK0AnEZ6kHsaSd94Qon6LiRFthosKftg9+5AD2BD4Huk59IeySv7G+ArM1tHUneS6ERB5sOuHBsC6wCfkKYyrjKzPpKOJolsHFOibFfSFv7VSTcva3h6T6C7mX3iD7iXYqDX08PMZkpaVkkC8lpgOzN7WdI/Se/FBc3UtTawDbAE8JKkS0l3h+sXe4bPdzwOBFj1kN+zXN+dC2ULgiCoOCEZ2TImAdtLOkfSlmY2Le/6JsBoM/vQnycbMm8Vc7EZcKuf35RJ3wIYbGazzOw/wMPAxnlltwJuADCzicDEEu201K4c48zsPTObQdoI8ICnTyI5zVLcYmbfmdkrJMe+tqePaMG0SF/gcp+Wwcv9CHjdzF72PNeR3ovmuMc3N3wEfAAs31wBM7vCzHqbWe9wzEEQtCeVHDnXGhUfOftIrSfwU+BMSSMr3UYVmInfyEhqIglY5MiGWvou8/o7mn9/82/7cq//O39mlsXsvjBHxzlHti+ziEftgiCoYRr5caO2WHNekTSVfANJM7gn8AVpqhTgSeDHkrpI6gTs1UyVTwB7+Pk+mfRHgf6+5rocaWQ4Nq/sI8Av3K71ge4l2ill11TSdDfAzkCnZmwul70kNfna9GrMic3aEkYAhypt7UfSsl5P18w0+f6kmQWYuy970DzZzy4IgqBmqOBu7ZqjLW48NgDG+s61U4AzSQ9+3yfpITN7DzgVeBwYQ9oZV4pjgGMlTQTWIK0HA9xBmqZ+FhgF/KGAFOOlwOKSXgBOB54q1kgzdl1JctzPkqbZKzWyfZN0Q3EvaYff9Pmo4yqvZ6Lb9wuv5yDgVkmTSKP4yzz/acCFksaTRscl8ef3xviGs9gQFgRBzdDI09oyq+07CqXno7/258n2AfY1s/yYp3WHpGuBu82sas8wV5qNb3mstr9M80EIX9QP2/188Wqb0CY0qvDFukvv1GqXeeaEB8v+zTlxo7515aLrYU2xFzBIkoDPgF9V2Z4gCIKgBqikZGStUTPOWdIJzLv+fKs/b7Zhhdt6Elg4L3l/M5tUyXa8rWL9GtDCen5CkijL8rqZ7dYK8yrK4H6fVtuEoEx+c9bS1Tah4vzzlcac5bj+1caUwvxLWbEaS1OP09XlUjPO2Z3wWe3U1ibt0Y63VZF+mdn9pOg1QRAEAeGcgyAIgqDm6NTAz1KFcw6CIAjqklhzDoIgCIIaI6a1gyAIgqDG6FBtA9qQhpuxd6Wou4tcm63IVEY9p0o6rrLWtRxXjrqoiu13lfSLarUfBEFQjEYOQhIj5xpGSc95PDC+imZ0JYVAvamZfEEQBO1KpzoMy1kuFRs5S7pT0lOSJksaKOmwbLhH1yke5OcnSXpJ0mOSBpcaoUra2HWKn5HrN3v6IpKucb3iCZK2KVC2i6QH3KargJL3T5JOcG3lx0jKTrn00ZJ6+/n3JE3N9OlOSSN8VH6EpGPdnic8znWxtkZLutD79ZykPp5+qqTrJY0Bri81E+D5F8+8DxMl7eHp+3rac5LOyeT/MnO+p0cqy+lLXyTp30p6zjn96rOBLd3O3xVof6CSJvX4m6+5r9TbGwRBUFEaeeRcyWntX5lZL6A3cBQp9nU2QEZ/4GZJG5MEFzYEdvT8pbgGONT1hLOxoA8HzMw2APYFrlPSMc5yCvCYma3n9qxSrBFJvUjCGj1Iilr58pPFWJ+kLb0x6Xnmr8xsI1KM7gOaKbuY9+u3wNWZ9HWBvma2bxntnwRMM7MNzKw7MMrFR84BtvX+bCxp1zLqWoEkxbkTySlD0nN+1IXEz88vkJWM3OegfmU0EQRBUBnCOZfHUS688ATwQ6AbMEXSppK6kLSKxwCbA3eZ2XQz+wL4V7EKJS0NLGFmj3tSvp5zTqv5ReANYK28KrJ6zvcApUJYbQncYWZfmdnnwLAy+gzwkJl9YWYfkkQ5cv0pR895sNv2CLCk9xdgmJmVG+6oL3BJ7oWZfUq6UchpU88EbqQ8Pec7XV/6ecrQcg6CIKgmlXTOkvr5jO6rko4vcH1hSUP8+pOSumau/cnTX/Jojq2mImvOkrYmOYnNzOwrSaNJWsE3A3sDL5Icn6UQ2XVHuRrI9aDnnG2zVF/q8oMKgmDBoUOFnnOW1IE0yNkeeBsYJ2mYD1RyHAx8amZruAjTOSTZ4nVJs67rASsCD0pay8yaVf0rRaVGzkuRjP5K0trApp5+B7ALadr5Zk8bA/zc14wXJ02hFsTMPgO+kJQLt5mv57wfgKS1SFPW+XrIWT3nHYFlSvThEWBXSYtKWgL4eebaVOZoIO+ZX7AV9HfbtiBNTU9rJn8hRpCm+PG6liHJUP7Y18c7kN7/nJ7zfyStI6mJuZcdihF6zkEQ1CRNLTiaoQ/wqplNMbNvSP4qX/1wF+A6Px8KbKc02twFuNnMZpjZ68CrXl+rqJRzvg/oqKSbfDZpajs3xfoCsKqZjfW0caQp44kkHeNJzNFoLsTBwJVK+tCdM3n/DjQp6RUPAQaYWb4O3mnAVpImk9aF3yzWiJk97fU863aNy1z+G/AbSROAsh7FKpPpXudlpH7OD2cCy/jGr2eBbVyb+njgIVJ/njKzuzz/8cDdwL+B98qofyIwS9KzhTaEBUEQVIuOTeUf2c2rfgzMVLUS8Fbm9dueRqE8vlw4DehSZtkWUxU9Z0mLm9mXSlrNjwAD3TkWzevnxwMrmNnR7Whum+BT/8f5o1INwauf/6txn2toMFZcLFSp6oU3/tuYoTb+0nu7Vi+d3TH13rJ/c3brumPR9vzplH5m9mt/vT+wiZkdkcnznOd521+/BmwCnAo8YWY3ePo/gHvNbGjLezSHaj3nfIXP0y8CXFfMMTs/k/Qnkq1vAAPawb4gCIKgxqngLux3SBuZc6zsaYXyvC2pI2k59+Myy7aYqjhnM5sn4pSkS0g7ubNcaGbXkKabK4LvHB9Z4NJ2ZvZxpdrJtFesX1u3sJ6DgPwZgzFmdnih/NXgxKeWqrYJFWfHlRtzNNapqS33HFaHW6c25taI999v1b6imqXG9JzHAWtK6kZyrPvg+5UyDAMOJD0muycwyjc5DwNukvT/SBvC1iTt+2kVNRMhrL2cjDvgHu3RlrdXkX75Tco1lagrCIKgEaiUczazmZKOAO4nhey+2swmSzodGG9mw4B/kAJDvQp8gm9Q9ny3AM+Tnuw5vLU7taGGnHMQBEEQtIRKhu80s+HA8Ly0kzPn04G9ipQ9ixSEqmKEcw6CIAjqkoZTbsoQzjkIgiCoS+oxLGe5tPrGQy2QYWwvlBGqyEufLb5RZj1fNp+r7ZF0le9ur1b7AzxedxAEQc3QQeUf9UaMnGscSR1yz95VkQHAc8C7VbYjCIJgNk0VCt9Zi7Ro5Cyps6R7PFrUc5L6Z64tKuleSYd4vqsljVWST9zF89wjqbufT5B0sp+fLumQIm02Sfq7pBeVpBmH+wPjSNrO65nk7S1coPxBSjKQY5n3kab8vN0kPe71nZlJn0u2UdIgSQP8fKqkvyhJKo6X1FPS/ZJek3RYiba2lvSIvycvSbrMQ2oi6UtJ53nEr82KzQRk6uon6Wn/XEZ62rJKcpYTleQrc+/7qcpIdPrn2NWPFyRdqSSx+YB/pnuSlMNu9D4uWuo9DIIgaC9ClWoO/YB3zWxDM1ufFLYTYHGSGtNgM7sSOIH0DFgfYBvgXEmdSfGwt5S0FGnLec5ZbkmKFFaI3UnqTusC+wObQdJzBq4F+rtsZEfgN9mCklYghfDcnKRi1dzU8IXApV5fOaEtc7zp0o+Puk17kuKLn9ZMuT7AkW7X6qS+QgpT+qS/z4+VqkDScsCVwB5mtiFzdhOeBkxwGck/A/8sox9rApe4xOZnXudQYDywn8tGzvXgrzIh8V67u1whryAIgtbTUeUf9UZLnfMkYHtJ50jaMiPUcBdwjZnlHMAOwPFK8bBHkyKBrUJyXluRnOU9wOJKITy7mVm+aEWOLYBbXcrwfVK8aIAfAa+b2cv++jrmlUXchDnSid/QfDCTzXEZR+D6ZvJmyXmlSSSnmpOQnKE5MpCFGOuB1md5u1t4+izgtjLb3hR4xAOuY2afePoWuT6Y2Sigi6Qlm6nrdTN7xs+fonnJy7n0nFffaecyTQ6CIGg9UvlHvdGiNWcze1lST+CnwJm5KVSS0lQ/STdZCtYt0qhrLocraSHSFOkUkprS94BDSI6gVii0iJGVjITiUotZycjc61LvcTHJyOmVeIi9CKX6krV9FhBT2EEQ1Cx16HPLpqVrzisCX3mA73OBnn7pZOBTkh4mpCgrR0rpfkXSRgA+en2LNPX6OGkkfRzFp7QhOf49fO15eWBrT38J6CppDX+9P3NkEXM8SZJO7CKpE0UeIM9rKydLuV8m/Q1gXSWx7aWB7Zqpp1z6+Dp3E0k+suQUdhGeIClvdYO01uzpWUnNrYGPzOxzkvxlT0/vCXQro42QjQyCoOZo5JFzS6e1NwDG+nT1KSS5whxHA4tK+itwBtAJmKgk13hGJt+jwAe+dvkoKUj4oyXavI0kwfU8cAPwNEn7eDpwEHCrkmzkdyTpxdm4dOKppBuBMST5ylIcDRzu9c2W/DKzt4BbSDuWbwEmNFNPuYwDBrldr5P0r1uET58PBG73DWS5qftTgV6SJpJkPA/09NuAZf1zOQJ4mea5FrgsNoQFQVBLVFDPueaoimRkS9EcickupIDim/v6c93io9njzGynattSKfZ56JHa/zK1kMYVvmi4j4p/vNyYkzuNKnwx+aCtWj2enfDx3WV/kTfqslNdjZ/r5Tnnu306eSHgjHp3zEEQBEHrqcdHpMqlZpyzpA2Yd4f0DDPbpKXyimW0dQLzrj/f6sHLK0qpfpF2srekrieB/Ge59zezSfNvYeX4waIzq21CxXn4/XkenW8Ijl6vJoLfVZTTe35WbRPahFc/r5mf6ZqjgX1z7ThndzDtIuXYFgoiJdqqWL/coQdBEATEyDkIgiAIao4G9s3hnIMgCIL6pB4fkSqXcM5BEARBXVKPj0iVS5v0TZJJOi/z+jhJp1ao7h+5EMQzLtRwRSXqLbPt2QIYkpaXdLeLTTwvaXgZ5Vslr6kk+lEqHGihModJOmB+2wyCIKhV2kv4woWERkh6xf8uUyTfgZ7nFUkHZtJHu8DRM358v9m+tc7koswAdm+NIyrBRcD5LsKwDnBxayuU1GE+ip0OjHBxinWB41trR3OY2U/NrEVbUs3sskzM8yAIgoZBLThayfHASDNbExhJgd97j854CknToQ9wSp4Tz4kH9TCzD5prsK2c80zgCuB3+RckXesyhLnXX/rfrSU9LOkuSVMknS1pPyXZyUmSVvciK5AihgGzd0MjqYOkv7kE4kRJR3p6QVlJH8WeI+lpYC9JOyjJRT4t6VZJi3u+fkpylU8zRzWqkB0TM/0oKC/p/MFtGZsLPervyaVK0o5TvI6rfWbg2kxdUyV9T0WkO/09e977/zdPmy0RKamHtzFR0h25L47f1Z3jNr0saUtPX8/TnvEyazbzuQdBELQbkpV9tJJdSOJK+N9dC+T5CWnA9omZfUrSj+g3vw225ZT9JcB+SvKQ5bIhcBiwDilW9louO3kVSVoR4HxglJJ29O8y07wDSSpKPVwm8UY1Lyv5sZn1BB4ETgT6+uvxwLFe/krg50Av4Ad5/fuHpIcknaAUd7wcprktg4ALMunLkOQwf0dSuTofWA/YQFL+o1jzSHcqRU/bDVjP+38m8/JP4I9+fRLpLi9HR3+vj8mkHwZc6HKYvcncjORQRjJy0p13518OgiBoM1oycs7+VvkxsAVNLe/hoAHeB5YvkGclknZEjrfJhIEGrvGBzklS81vZ2sw5u8jCP4GjWlBsnJm9Z2YzgNeABzx9Ei5faGbXkJz3rSQRjCd8NNwXuNzMZnq+T2heVjIXh3pTkqbyGKW44QcCqwJre/lXXG3rhkz/7gdWIznvtYEJStrKzTE483ezTPq/vI1JwH/MbJKZfQdMZl7pxkLSndOA6aQbht2Br7IF/CZpaTPLiYPkvxe3+9+sVOTjwJ8l/RFYNV/LGeaWjNxg14aJRBoEQR3QEuGL7G+VH1fMXZce9JnI/GOXbD7/nW7pUHw/H5Rt6cf+zRVo681uFwAHA50zabMlC5XUmBbKXMuXW8xKMc7eWW5m75rZ1Wa2i9e3/nza91//K9J0RG49YF0zO7i5wj59cZOZ7U8SsdiK5uUlrch52bKTfrPRk+Skz5R0st+U9AGGAjsB9zVnfx65Nmfl2jOzm4Cdga+B4ZK2bWGdQRAEbUYHlX80h5n1NbP1Cxx3Af+RtAKA/y20ZvwO8MPM65U9DTPL/f0CuIn0W12SNnXOPnq9heSgc0wlTRFD+uHv1JI6fQ24k5//AOhCegNGAIdK6ujXlqU8WUlIsoubZ9aAO0taC3jRy+fWu/fN2LGtpMX8fAlgdeBNmpeX7J/5+3hL+p5pex7pTl8jX8rMhpOmxjfMlvHR9ae59WSKvxfZdlYDppjZRcBdQPf5sTcIgqAtaMcNYcOYo+x3IOn3MJ/7gR0kLeP7eXYA7pfUUb452n3XTiSFw5K0x3PO55GkCXNcCdylJG94H3NGr+WyA3ChpOn++vdm9r6kq4C1SDKV3wJXmtkgSTlZyY6k0e1l+RWa2Ye+aWuwT5EDnGhmL/u6xD2SviJJW+akb3oBgyTlRspXmdk4AEk5ecnXmVdechklGccZZJx9C9kAOFfSd8C3pHX0JUjv6yKk7+KxBcodSJJ+XAyYQpLcLMXewP7+fr4P/N982hsEQVBx2jEIydnALZIOJg3A9k7tqzdwmJn92sw+kXQGyc8AnO5pnUlOuhPQgbTH6crmGqwLycigPjjmiVEN92X6/NvGDHPQiMIXX37bmOGiGlX44sA1f9LqD+zt//6r7N+clTv/vK6+II35qQdBEAQNTwhfBEEQBEGN0cC+OZxzUDm2WP6bapsQlMkr0+K/fr3QuWPDrRZVjKbWBxepWeJ/aBAEQVCXhCpVEARBENQYDeybwzkHQRAE9UljPkuRaOS+1QRK0pI3uaDFU0riGru1cZs5ebKJSqIdg9RCqckgCIJapyXhO+uNcM5tiAc3vxN4xMxWM7NewD6ksG7ZfG0xg7GfC1x0JwU8KRTRJgiCoG4RTWUf9Ub9WVxfbAt8Y2azo5KZ2RtmdrGkAZKGSRoFjFQS877TR7tPSOoOc0s++uvnJHX140VJNypJSw7NhRPNYmbfAH8AVpG0oZd7LlPfcZJO9fPRks53xZYXJG0s6XYl4fBCKldBEARVQ2oq+6g36s/i+mI94OkS13sCe5rZj4HTgAk+2v0zSdGrOX4E/N3M1gE+B35bKJOZzQKeJalnNcc3ZtabFOb0LuBwkrDIAJelDIIgqBHaMbp2OxPOuR2RdImkZyXlYq+OcHEQgC2A6wHMbBTQRdKSzVT5lpmN8fMbvI6izZdp5jD/OwmYnJHwnMLciiup0oxG6ojBw8tsIgiCoPWoBf/qjdit3bZMBvbIvTCzw12dZLwnlSP6UUqCMv8J/IJP5EvqQBLLeKGZ+qAF0pWQNFKBKwCGvn5f40YECIKgBqk/p1suMXJuW0YBi0j6TSZtnnVh51FgPwBJWwMfmdnnJInNnp7eE+iWKbOKpM38/BfAY/mVuhLKX0ij7InAf4DvS+riClw7zV/XgiAIqksjrznHyLkNMTOTtCtwvqQ/AB+SRst/BBbNy34qcLXLSX7FHO3Q24ADJE0GngRezpR5CThc0tXA88ClmWs3SpoBLEySKNvFbfpW0unAWJIO9osV6m4QBEG7Uo+7sMslJCPrFEldgbvNbP0qmzKbmNYOgqBc9uzWr9Vz0l9+W75M7eKdtq2rOfAYOQdBEAR1SuOOnMM51ylmNpX0iFMQBMECieox9FeZhHMOKsZB2w6ptgkVZ+as6dU2oU1YYdf+1Tah4nx097DmM9Uh6577q2qb0Cbs2a35PM3TPs5Z0rLAEKAraZPu3mb2aYF89wGbAo+Z2U6Z9G7AzUAX4Clgfw8QVZTGnRMIgiAIGpp2fM75eGCkma0JjPTXhTgX2L9A+jnA+Wa2BvApcHBzDYZzDoIgCOoS0aHso5XsAlzn59cBuxbKZGYjgS/msjHNvW8LDG2ufJZwzkEQBEFdIqklx+xohn4MbEFTy5vZe37+PrB8C8p2AT4zs5n++m1gpeYKxZpzEARBUKeUP12djWZYsCbpQeAHBS6dkFePSWrzx0bDOQdBEAR1SSWDkJhZ36LtSP+RtIKZvSdpBeCDFlT9MbC0pI4+el6ZFACqJC3qWb7cYCb9dElFO+Z55pI+nB8kHVNIFtGvDZA0qDX1VxJJK0oa2nzO9kHStZL2rLYdQRAElaPdVKmGMSdq44Ekxb6ysBTp6yEg9/tbVvmK3HaY2clm9mAl6mqGYygem7pm8Dukd80snGEQBEEb0Y6xtc8Gtpf0CtDXXyOpt6Sr5tijR4Fbge0kvS3pJ37pj8Cxkl4lrUH/o7kG58fiDpKulDRZ0gOS67oOyQAADNJJREFUFs2OyiT9VNKLkp6SdJGkuzNl15U0WtIUSUcVa0BSZ0n3uLzic5L6e/4VgYckPeT5DpL0sqSxwOaljJa0nKTbJI3zY3NPv0vSAX5+qKQb/Xy0pAslPeM29MnYdrWksZImSNrF0wdIGiZpFDAyO8sgqYOkc73diZIO9fStvZ2h/p7d6Dv7kLSxpH/7ezBW0hLF6inSX0kaJOklX0v5fubaVCV1rNyXa7SfnyrpOkmPSnpD0u6S/ippkqT7lEQ0giAIagLRVPbRGszsYzPbzszWNLO+OalfMxtvZr/O5NvSzJYzs0XNbGUzu9/Tp5hZHzNbw8z2chnekszPmvOawL5mdoikW8hIIkpaBLgc2MrMXpc0OK/s2sA2wBLAS5IuNbNvC7TRD3jXzH7m9S5lZtMkHQtsY2Yf+bz/aUAvYBpp2mBCCbsvJD1n9pikVYD7gXWAgcAYSa8D/0t6gDzHYmbWQ9JWwNWkiFwnAKPM7FeSlgbGuvODpB7V3cw+UYp9neNgYJqZbaykBDVG0v9v785j5SrrMI5/n1YFgoCAGosR17AJagmlooiyaIIalMX0H4xBIgkaMFHiPxpUUIwxLsGgAVziEgkQgsSoUAOyKTs0EDYRQcWCskhlh9Kff5xz7VCvXe4MPfM+Pp+k6czce2fe721z3znnPfecpf3HFgJvBJYDvwPe3r/ZOBNYUlXXqLuu8xP/63mq6q5Zeg8GdgR2oTuy8Ja+YV1eT/dvtAtwBXBoVX1G0rnA+4Cfj36yuiMejwLYZNu9eOEWO67HS0RETELOEDbqrqpa1t++ju6MKTN2Av40MlmcQf+Du/fL/h3DU5L+QTdp3DPLa9wEfF3SV+ku7nDZLJ+zGLi4qu4HkHQmsMNaxn0A3Zb7zP0tJb24qv4u6Xi6yf3gmXdEI+Onqi6VtGU/Gb8HOEir1883Bbbvb/9mja+f8R7gTVq95rsV3Zucp4Grq+qevmEZ3fdzBXBvVV3Tv/6/+o//r+eZbXLeBzijqp4Flvdb9Ovj1/2Vq24C5gPn94/fxHP/renH9p8jILd47RG58EVEbDQTOLnI1JrL5Dy6Of4s/33pww352llfv6r+oO7axe8FviTpwqo6YYNH+lzzgLdW1WznY9yN7oi67dYcyiz3Rbc1efvoByQtprsc5GwEHDOzi2Pka97Fen5P1vY8c7CS1Usam67xsacAqmqVpGdq9WXLVq1jbBERG5WMz6096ZOQ3A68bmSX7pxO4CtpO+Dxqvop3enQdu8/9AjdLnHorm38Tknb9muhH1rH0y4Fjhl5jbf0f+8JHEi3e/k4dedAnbGk/5y96XYnr6DbHX7MyNrwwvVIugA4embNVtIOkjZfy+ffDiyQtKj//C0kvWADn+dSYEm/Tr2Ablf1jLvplgNgZFkiIqIt8zbgT1smuiVUVU9I+jhwvqTHgGvm+FS7AV+TtAp4Bji6f/y0/rmXV9W+kr5Aty76MLBs1mda7VjgFEk30nVfKumTwOnAEVW1XNKngR9I2q//micl3QC8EJg5+/yJwLeAG9UdAngX8H7W7nt0u4Sv7yf1+1nL6duq6mlJS4BvS9qMbr35gA18nnPpThl3C/AXuu/TjC8C35d0InDxOsYeETGVJvl7ztNGq/daTugJu3XcR/vJ4xTgjqr65kRfZCPoj2A+rqquHXosrXBcc85VqdqRq1K15cpD9x57n3Rx63r/zBE7N7UP/Pl42/Gx/sCmm+kOWDr1eXiNiIj4v+e7W3viW84b9OLStnSX31rT/lX14Byf87P89/rz2VX15bk837STtBvwkzUefqqqFg8xno1F0lH9keJWHLscm8Czy7GpVYNOzhFzJenaqtpj6HFMmmOXYxN4djk2taq9bf2IiAhzmZwjIiKmTCbnaJXruphjl2MTeHY5NjUpa84RERFTJlvOERERUyaTc0RExJTJ5BwRETFlMjlHRERMmUzOMfUkvXSN+4dLOlnSUTNXB2uNYxN4djk2gW+Xi0zO0YKlMzckfQ74MHAd8G7gG0MNakyOTeDZ5dgEvl0WJnrJyIjnyei7+EOAd1TVY5J+Blw/0JjG5dgEnl2OTeDbZSGTc7RgM0kL6fb0zK+qxwCq6hlJzw47tDlzbALPLscm8O2ykMk5WnAvq3ezPSRpQVXd21/VbOWA4xqHYxN4djk2gW+XhZwhLJolaT6wSVU9PvRYJsWxCTy7HJvAt6s1OSAsmqHO4ZKO7x96JbDrkGMal2MTeHY5NoFvV+uy5RzNkPRdYBWwX1XtLGlrYGlVLRp4aHPm2ASeXY5N4NvVuqw5R0sWV9Xukm4AqKp/SnrR0IMak2MTeHY5NoFvV9OyWzta8ky/HlYAkl5G946/ZY5N4Nnl2AS+XU3L5BwtORk4F3i5pC8DlwMnDTuksTk2gWeXYxP4djUta87RFEk7AfvTnUDhwqq6deAhjc2xCTy7HJvAt6tlmZxj6knaZm0fr6qHNtZYJsWxCTy7HJvAt8tFJueYepLuolsPm+1k/FVVr9vIQxqbYxN4djk2gW+Xi0zOERERUya/ShVNkXQIsDfdO/7LqurnAw9pbI5N4Nnl2AS+XS3LlnM0Q9J3gDcAZ/QPLQHurKpPDDeq8Tg2gWeXYxP4drUuk3M0Q9JtwM7V/6eVNA+4uap2HnZkc+fYBJ5djk3g29W6/J5ztOSPwPYj91/VP9Yyxybw7HJsAt+upmXLOZoh6RJgEXB1/9Ai4FpgBUBVHTTQ0ObMsQk8uxybwLerdTkgLFpy/Lo/pTmOTeDZ5dgEvl1Ny5ZzNEfSloy8sXQ4WYJjE3h2OTaBb1ersuUczZB0FHAC8CTdiflF96sfzZ4swbEJPLscm8C3q3XZco5mSLoD2KuqHhh6LJPi2ASeXY5N4NvVuhytHS25E3h86EFMmGMTeHY5NoFvV9Oy5RzNkLQQ+CFwFfDUzONVdexggxqTYxN4djk2gW9X67LmHC05FbgIuAmfi8E7NoFnl2MT+HY1LVvO0QxJN1TVwqHHMUmOTeDZ5dgEvl2ty+QczZB0EnA38Aueu/ut2V/5cGwCzy7HJvDtal0m52hGf/3ZNTV93VnHJvDscmwC367WZXKOiIiYMjkgLJoiaVdgF2DTmceq6sfDjWh8jk3g2eXYBL5dLcuWczRD0ueBd9H9EPkVcCBweVUdNuS4xuHYBJ5djk3g29W6nIQkWnIYsD9wX1UdAbwZ2GrYIY3NsQk8uxybwLeraZmcoyVPVNUqYGV/kv5/0F17tmWOTeDZ5dgEvl1Ny5pztORaSS8BTgeuAx4Frhh2SGNzbALPLscm8O1qWtaco0mSXgNsWVU3DjyUiXFsAs8uxybw7WpRtpxj6kl6NfBwVa3o7+8LfBD4s6TbqurpQQc4B45N4Nnl2AS+XS6y5hwtOAvYHEDSW4Czgb/QHbjynQHHNQ7HJvDscmwC3y4L2XKOFmxWVcv724cDP6iqr0uaBywbcFzjcGwCzy7HJvDtspAt52iBRm7vB1wI0B9h2irHJvDscmwC3y4L2XKOFlwk6SzgXmBrusvbIWkB0Oq6mGMTeHY5NoFvl4UcrR1TT5KAJcAC4Kyq+lv/+ELg5VV1wZDjmwvHJvDscmwC3y4XmZyjKZJeAewJFHBNVd038JDG5tgEnl2OTeDb1bKsOUczJB0JXA0cQnfKwSslfXTYUY3HsQk8uxybwLerddlyjmZIuh14W1U92N/fFvh9Ve047MjmzrEJPLscm8C3q3XZco6WPAg8MnL/kf6xljk2gWeXYxP4djUtR2vH1JP0qf7mH4GrJJ1Htzb2AaDJ0ww6NoFnl2MT+Ha5yOQcLdii//vO/s+M8wYYy6Q4NoFnl2MT+HZZyJpzRETElMmWczRD0m/pdrs9R1XtN8BwJsKxCTy7HJvAt6t1mZyjJceN3N4UOBRYOdBYJsWxCTy7HJvAt6tp2a0dTZN0dVXtOfQ4JsmxCTy7HJvAt6sl2XKOZkjaZuTuPGAPYKuBhjMRjk3g2eXYBL5drcvkHC25jtVrYyuBu4EjBxvNZDg2gWeXYxP4djUtk3NMPUmLgL9W1Wv7+x+hWxe7G7hlwKHNmWMTeHY5NoFvl4ucISxacCr9Jewk7QN8BfgRsAI4bcBxjcOxCTy7HJvAt8tCtpyjBfOr6qH+9hLgtKo6BzhH0rIBxzUOxybw7HJsAt8uC9lyjhbMlzTzRnJ/+ovC91p9g+nYBJ5djk3g22Uh/wDRgjOASyQ9ADwBXAYg6Q10u+Ba5NgEnl2OTeDbZSG/5xxNkPRWYAGwtKoe6x/bAXhxVV0/6ODmyLEJPLscm8C3y0Em54iIiCmTNeeIiIgpk8k5IiJiymRyjoiImDKZnCMiIqZMJueIiIgp828i8v+HRZqUcwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}